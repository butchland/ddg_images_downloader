{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duckduckgo Image Downloader \n",
    "> Provides an image downloader using duckduckgo image search.\n",
    ">\n",
    "> This library requires selenium and chromedriver\n",
    "> in order to fetch image urls\n",
    "> and reuses the fastai image utilities to download the images.\n",
    ">\n",
    "> Because all the urls come from the duckduckgo site,\n",
    "> a slow version of download_images is provided in order\n",
    "> to not bombard the site with simultaneous requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Optional) Run the following command to setup fastai in Colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab\n",
    "#!curl https://course.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Instructions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install Chrome Driver (done one-time per environment only)\n",
    "\n",
    "**Make sure that chrome and chromedriver are both accessible in the PATH variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome_linux_install\n",
    "# install chromium, its driver\n",
    "!apt-get update\n",
    "!apt install chromium-chromedriver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Install python libraries (done one-time per environment only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip_install\n",
    "# install python libraries and fastai2\n",
    "!pip install selenium\n",
    "!pip install beautifulsoup4\n",
    "!pip install html5lib\n",
    "!pip install fastcore\n",
    "!pip install fastai2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the actual usage, running the following pip install will install all the requirements so the above step to install the required libraries will be a redundant step**\n",
    "```\n",
    "pip install git+https://github.com/butchland/ddg_images_downloader.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#!pip install git+https://github.com/butchland/ddg_images_downloader.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup selenium webdriver to use headless Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "# set options to be headless, ..\n",
    "from selenium import webdriver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automate search via selenium accessing DDG Image Search\n",
    "\n",
    "> The following methods fetch the image urls retrieved from DDG Image Search into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "import time\n",
    "DDG_SEARCH_URL = 'https://start.duckduckgo.com'\n",
    "# DDG_IMAGE_SEARCH_URL = 'https://duckduckgo.com/?q=%s&t=h_&iar=images&iax=images&ia=images'\n",
    "\n",
    "def get_browser_page(search_string, options=chrome_options, scroll_count=20, sleep=3):\n",
    "    \"retrieves a ddg page containing image search results for `search_string`, scrolling down `scroll_count` times, with a delay of `sleep` seconds between scrolls\"\n",
    "    browser = webdriver.Chrome(options=options)\n",
    "    browser.get(DDG_SEARCH_URL)\n",
    "    wait = WebDriverWait(browser,10)\n",
    "    input_elt = wait.until(\n",
    "        EC.presence_of_element_located((By.ID, \"search_form_input_homepage\"))\n",
    "    )\n",
    "    submit_elt = browser.find_element_by_id('search_button_homepage')\n",
    "    input_elt.send_keys(search_string)\n",
    "    submit_elt.click()\n",
    "    images_link = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \".js-zci-link--images\"))\n",
    "    )\n",
    "    images_link.click()\n",
    "    wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \".tile--img__img\"))\n",
    "    )\n",
    "    for i in range(scroll_count):\n",
    "        browser.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(sleep)\n",
    "    page_source = browser.page_source\n",
    "    browser.quit()\n",
    "    return page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465728"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_source = get_browser_page('coconut fruit',scroll_count=3,sleep=1);len(page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ne(page_source,None)\n",
    "test_eq(type(page_source),type('a string'))\n",
    "test_ne(len(page_source),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "page_source = get_browser_page('teddy bear');len(page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "from bs4 import BeautifulSoup as bs\n",
    "def extract_images(page_source):\n",
    "    page = bs(page_source,\"html5lib\")\n",
    "    img_elts = page.find_all(\"img\",attrs={\"class\":\"tile--img__img\"})\n",
    "    return img_elts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_elts = extract_images(page_source);len(img_elts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ne(img_elts,None)\n",
    "test_ne(len(img_elts),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "import re\n",
    "from urllib.parse import unquote\n",
    "DATA_SRC_URL_PATTERN = r'^//external-content\\.duckduckgo\\.com/iu/\\?u=(.*)$'\n",
    "\n",
    "def extract_url(img_elt):\n",
    "    data_src = img_elt.attrs['data-src']\n",
    "    if data_src:\n",
    "        url_match = re.match(DATA_SRC_URL_PATTERN,data_src)\n",
    "        if url_match:\n",
    "            return unquote(url_match.group(1))\n",
    "    return None\n",
    "\n",
    "def extract_img_urls(img_elts):\n",
    "    img_urls = [url for url in map(extract_url, img_elts) if url is not None]\n",
    "    return img_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_urls = extract_img_urls(img_elts);len(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://tse1.mm.bing.net/th?id=OIP.Mjd00HrSTlk7nWWCCiAU6wHaEx&pid=Api&f=1',\n",
       " 'https://tse2.mm.bing.net/th?id=OIP.Y2g2YJqtmQz1Q9CsvgVGXAHaHJ&pid=Api&f=1',\n",
       " 'https://tse3.mm.bing.net/th?id=OIP.BAto6DRbdswy9SkluCsnegHaLH&pid=Api&f=1')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img_urls[0],img_urls[50], img_urls[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(len(img_urls),0,operator.gt)\n",
    "test_eq('https://',img_urls[0][:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Image URLs\n",
    "\n",
    "> get image urls given a search string while scrolling down (with sleep in between scrolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# combine everything into 1 \n",
    "def get_image_urls(search_string,options=chrome_options,scroll_count=20,sleep=3):\n",
    "    \"get image urls with `search_string` and scroll down `scroll_count` times with a delay of `sleep` seconds returns a list of urls\"\n",
    "    page_source = get_browser_page(search_string,options=options,scroll_count=scroll_count,sleep=sleep)\n",
    "    img_elts = extract_images(page_source)\n",
    "    img_urls = extract_img_urls(img_elts)\n",
    "    return img_urls\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_urls = get_image_urls('apple fruit', scroll_count=3,sleep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(len(img_urls),0, operator.gt)\n",
    "test_eq('https://', img_urls[0][:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "from pathlib import Path\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download search terms retrieved image urls into files\n",
    "\n",
    "> This will download each search term into a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def download_search_urls(path,search_terms, search_pattern, file_pattern='{0}.txt',\n",
    "                      options=chrome_options,scroll_count=20,sleep=3):\n",
    "    \"download search results into a file in named after search string\"\n",
    "    path.mkdir(exist_ok=True)\n",
    "    for o in search_terms:\n",
    "        results = get_image_urls(search_pattern.format(o),options=options,scroll_count=scroll_count,sleep=sleep)\n",
    "        print(search_pattern.format(o), len(results))\n",
    "        with open(path/file_pattern.format(o), 'w') as f:\n",
    "            f.writelines(\"%s\\n\" % line for line in results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "> Download Bear Images for fastai lesson on creating your own dataset using bears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "!rm -rf bears\n",
    "bear_types = ['grizzly','black','teddy']\n",
    "path = Path('bears')\n",
    "download_search_urls(path, bear_types, '{0} bear', scroll_count=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panda bear 344\n"
     ]
    }
   ],
   "source": [
    "bear_types = ['panda']\n",
    "path = Path('bears')\n",
    "download_search_urls(path, bear_types, '{0} bear', scroll_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [Path('bears/black.txt'),Path('bears/panda.txt'),Path('bears/teddy.txt'),Path('bears/black'),Path('bears/teddy')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bear_path = path.ls();bear_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_is(Path('bears/panda.txt') in bear_path,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images from files stored in path\n",
    "\n",
    "> The following methods retrieves the images from stored urls in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "# externalized version of fastai2 internal method _download_image (copied exactly)\n",
    "# see https://github.com/fastai/fastai2/blob/master/fastai2/vision/utils.py#L19\n",
    "from fastai2.vision.utils import download_url\n",
    "def download_image_inner(dest, inp, timeout=4):\n",
    "    i,url = inp\n",
    "    suffix = re.findall(r'\\.\\w+?(?=(?:\\?|$))', url)\n",
    "    suffix = suffix[0] if len(suffix)>0  else '.jpg'\n",
    "    try: download_url(url, dest/f\"{i:08d}{suffix}\", overwrite=True, show_progress=False, timeout=timeout)\n",
    "    except Exception as e: f\"Couldn't download {url}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slow version of download images \n",
    "> This is to allow the program to not overwhelm the duckduckgo server with simultaneous requests\n",
    "> but allow it to pause the query with a configurable delay between image requests (default to 3 secs per batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def download_images_slowly(dest,url_file=None, urls=None, max_pics=1000, delay=3, batch_size=10,timeout=4):\n",
    "    \"Download images listed in text file `url_file` to path `dest`, at most `max_pics` with a delay of `delay` secs for every batch of `batch_size` images with only 1 thread\"\n",
    "    if urls is None: urls = url_file.read().strip().split(\"\\n\")[:max_pics]\n",
    "    dest = Path(dest)\n",
    "    dest.mkdir(exist_ok=True)\n",
    "    for inp in enumerate(urls):\n",
    "        i,_ = inp\n",
    "        download_image_inner(dest,inp,timeout=timeout)\n",
    "        if i % batch_size == 0:\n",
    "            print(f'downloaded: ', i, ' dest: ', dest)\n",
    "            time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def download_search_images_slowly(path, search_terms, file_pattern='{0}.txt', \n",
    "                                  max_pics=1000, delay=3, batch_size=10,timeout=4):\n",
    "    \"Download images listed in text file for each item in `search_terms`  to path `dest`/item, at most `max_pics` with a delay of `delay` secs for every batch of `batch_size` images with only 1 thread\"\n",
    "    for o in search_terms:\n",
    "        download_images_slowly(path/o,path/file_pattern.format(o),max_pics=max_pics, delay=delay,\n",
    "                               batch_size=batch_size, timeout=timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "download_search_images_slowly(path,bear_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "bear_path = path.ls()\n",
    "test_is(Path('bears/panda') in bear_path,True)\n",
    "panda_bears = (path/'panda').ls()\n",
    "test(len(panda_bears),0,operator.gt)\n",
    "test_eq(panda_bears[0].as_posix()[:14],'bears/panda/00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_images.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
